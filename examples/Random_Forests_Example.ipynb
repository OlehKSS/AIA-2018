{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example file showing random forest implementation for our data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "import immas\n",
    "from immas import MammogramImage\n",
    "from immas import get_img_features\n",
    "from immas.basic_functions import show_image_plt\n",
    "from immas import get_dataset_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>perimeter</th>\n",
       "      <th>area</th>\n",
       "      <th>circularity</th>\n",
       "      <th>ac</th>\n",
       "      <th>mean_intensity</th>\n",
       "      <th>standard_deviation</th>\n",
       "      <th>smoothness</th>\n",
       "      <th>skewness</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1867</th>\n",
       "      <td>1868</td>\n",
       "      <td>899.095453</td>\n",
       "      <td>14885.5</td>\n",
       "      <td>4.321538</td>\n",
       "      <td>3444.491487</td>\n",
       "      <td>33043.337140</td>\n",
       "      <td>18935.918275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.263530e+10</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3390</th>\n",
       "      <td>3391</td>\n",
       "      <td>172.727922</td>\n",
       "      <td>1420.5</td>\n",
       "      <td>1.671375</td>\n",
       "      <td>849.898855</td>\n",
       "      <td>34477.479416</td>\n",
       "      <td>18878.973700</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-3.117625e+11</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1589</td>\n",
       "      <td>452.526911</td>\n",
       "      <td>6216.5</td>\n",
       "      <td>2.621398</td>\n",
       "      <td>2371.444238</td>\n",
       "      <td>33082.684734</td>\n",
       "      <td>18999.996360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.163013e+11</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2380</th>\n",
       "      <td>2381</td>\n",
       "      <td>167.656854</td>\n",
       "      <td>1114.0</td>\n",
       "      <td>2.007925</td>\n",
       "      <td>554.801491</td>\n",
       "      <td>33239.545910</td>\n",
       "      <td>19124.833629</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.425216e+11</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1445</td>\n",
       "      <td>248.727922</td>\n",
       "      <td>2068.5</td>\n",
       "      <td>2.380037</td>\n",
       "      <td>869.104166</td>\n",
       "      <td>32677.747719</td>\n",
       "      <td>18878.957259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.236997e+11</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0   perimeter     area  circularity           ac  \\\n",
       "1867        1868  899.095453  14885.5     4.321538  3444.491487   \n",
       "3390        3391  172.727922   1420.5     1.671375   849.898855   \n",
       "1588        1589  452.526911   6216.5     2.621398  2371.444238   \n",
       "2380        2381  167.656854   1114.0     2.007925   554.801491   \n",
       "1444        1445  248.727922   2068.5     2.380037   869.104166   \n",
       "\n",
       "      mean_intensity  standard_deviation  smoothness      skewness  class_id  \n",
       "1867    33043.337140        18935.918275         1.0  1.263530e+10      -1.0  \n",
       "3390    34477.479416        18878.973700         1.0 -3.117625e+11      -1.0  \n",
       "1588    33082.684734        18999.996360         1.0  1.163013e+11      -1.0  \n",
       "2380    33239.545910        19124.833629         1.0 -1.425216e+11      -1.0  \n",
       "1444    32677.747719        18878.957259         1.0 -1.236997e+11      -1.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the data\n",
    "data = pd.read_csv(\"classifier-train-data.csv\")\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Separate the features(X) from the labels(y)\n",
    "X_all = data.drop(['class_id', 'Unnamed: 0'], axis=1)\n",
    "y_all = data['class_id']\n",
    "\n",
    "# Train 80% of data, test 20%\n",
    "num_test = 0.20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=num_test, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "            max_depth=3, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=5, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=4, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit and tune the algorithm\n",
    "\n",
    "# Choose the type of classifier. \n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "# Choose some parameter combinations to try\n",
    "parameters = {'n_estimators': [4, 6, 9], \n",
    "              'max_features': ['log2', 'sqrt','auto'], \n",
    "              'criterion': ['entropy', 'gini'],\n",
    "              'max_depth': [2, 3, 5, 10], \n",
    "              'min_samples_split': [2, 3, 5],\n",
    "              'min_samples_leaf': [1,5,8]\n",
    "             }\n",
    "\n",
    "# Type of scoring used to compare parameter combinations\n",
    "acc_scorer = make_scorer(accuracy_score)\n",
    "\n",
    "# Run the grid search\n",
    "grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Set the clf to the best combination of parameters\n",
    "clf = grid_obj.best_estimator_\n",
    "\n",
    "# Fit the best algorithm to the data. \n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9894736842105263\n"
     ]
    }
   ],
   "source": [
    "predictions = clf.predict(X_test)\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 accuracy: 1.0\n",
      "Fold 2 accuracy: 1.0\n",
      "Fold 3 accuracy: 0.9887640449438202\n",
      "Fold 4 accuracy: 1.0\n",
      "Fold 5 accuracy: 0.9662921348314607\n",
      "Fold 6 accuracy: 0.9887640449438202\n",
      "Fold 7 accuracy: 1.0\n",
      "Fold 8 accuracy: 0.9887640449438202\n",
      "Fold 9 accuracy: 0.9887640449438202\n",
      "Fold 10 accuracy: 0.9775280898876404\n",
      "Mean Accuracy: 0.9898876404494381\n"
     ]
    }
   ],
   "source": [
    "# Validate with k-fold\n",
    "def run_kfold(clf):\n",
    "    kf = KFold(891, n_folds=10)\n",
    "    outcomes = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf:\n",
    "        fold += 1\n",
    "        X_train, X_test = X_all.values[train_index], X_all.values[test_index]\n",
    "        y_train, y_test = y_all.values[train_index], y_all.values[test_index]\n",
    "        clf.fit(X_train, y_train)\n",
    "        predictions = clf.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, predictions)\n",
    "        outcomes.append(accuracy)\n",
    "        print(\"Fold {0} accuracy: {1}\".format(fold, accuracy))     \n",
    "    mean_outcome = np.mean(outcomes)\n",
    "    print(\"Mean Accuracy: {0}\".format(mean_outcome)) \n",
    "\n",
    "run_kfold(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test data 855\n",
      "Number of masses in the test data 26\n",
      "[ 1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.  1.\n",
      "  1. -1. -1.  1.  1.  1.  1.  1.]\n",
      "Detected percentage of masses 0.8461538461538461\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many masses we managed to detect out of all regions\n",
    "x_test2 = X_test[y_test == 1]\n",
    "y_test2 = y_test[y_test == 1]\n",
    "\n",
    "print(f\"Length of test data {len(X_test)}\")\n",
    "print(f\"Number of masses in the test data {len(x_test2)}\")\n",
    "\n",
    "predictions = clf.predict(x_test2)\n",
    "\n",
    "print(predictions)\n",
    "print(f\"Detected percentage of masses {accuracy_score(y_test2, predictions)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test data 4273\n",
      "Number of masses in the test data 114\n",
      "Detected percentage of masses 0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "# let's test performance on the initial data\n",
    "x_test_all = X_all[y_all == 1]\n",
    "y_test_all = y_all[y_all == 1]\n",
    "\n",
    "print(f\"Length of test data {len(X_all)}\")\n",
    "print(f\"Number of masses in the test data {len(x_test_all)}\")\n",
    "\n",
    "predictions = clf.predict(x_test_all)\n",
    "print(f\"Detected percentage of masses {accuracy_score(y_test_all, predictions)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of saving classifier to the disk and loading it back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save our classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save the classifier\n",
    "with open(\"./models/rf_classifier.pkl\", \"wb\") as fid:\n",
    "    pickle.dump(clf, fid)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will load classifier and test it again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test data 4273\n",
      "Number of masses in the test data 114\n",
      "Detected percentage of masses 0.7719298245614035\n"
     ]
    }
   ],
   "source": [
    "# load it again\n",
    "with open(\"./models/rf_classifier.pkl\", \"rb\") as fid:\n",
    "    rf_classifier_loaded = pickle.load(fid)\n",
    "    \n",
    "# let's test performance on the initial data\n",
    "print(f\"Length of test data {len(X_all)}\")\n",
    "print(f\"Number of masses in the test data {len(x_test_all)}\")\n",
    "\n",
    "predictions_loaded = rf_classifier_loaded.predict(x_test_all)\n",
    "print(f\"Detected percentage of masses {accuracy_score(y_test_all, predictions_loaded)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
