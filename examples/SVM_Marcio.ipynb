{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets, preprocessing\n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, matthews_corrcoef, roc_curve, auc, make_scorer\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import AdaBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read dataset\n",
    "filename = 'C:\\\\AIA-2018\\\\examples\\\\feature-tables\\\\train-data_1526424532.csv'\n",
    "data = pd.read_csv(filename)\n",
    "\n",
    "#specify feature and target\n",
    "Feature = data.drop(['class_id', 'Unnamed: 0'], axis=1)\n",
    "Target  = data['class_id']\n",
    "\n",
    "# shuffle the dataset\n",
    "X = Feature.as_matrix()\n",
    "y = Target.as_matrix()\n",
    "X, y = shuffle(X, y, random_state=None)\n",
    "\n",
    "#standardize data (mean = 0)\n",
    "X = preprocessing.robust_scale(X)\n",
    "\n",
    "# Split the dataset in two equal parts\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train algorithm\n",
    "#svclassifier = SVC(C=10, class_weight={1: 10}, kernel='linear', probability=True, decision_function_shape='ovo')\n",
    "svclassifier = SVC(C=0.1, cache_size=200, class_weight={1: 10}, coef0=0.0,\n",
    "  decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
    "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "  tol=0.001, verbose=False)\n",
    "svclassifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.1, 1, 10, 100], 'kernel': ['linear'], 'class_weight': ['balanced', {1: 8}, {1: 10}, {1: 12}]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(matthews_corrcoef), verbose=0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search 1\n",
    "calculate_MCC = make_scorer(matthews_corrcoef)\n",
    "\n",
    "parameters = [\n",
    "  {'C': [0.1, 1, 10, 100], 'kernel': ['linear'], 'class_weight':['balanced',{1:8},{1:10},{1:12}]}\n",
    "]\n",
    "\n",
    "gridSVM = svm.SVC()\n",
    "grid_search1 = GridSearchCV(gridSVM, parameters, scoring=calculate_MCC)\n",
    "grid_search1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid=[{'C': [0.1, 1, 10, 100], 'gamma': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.5], 'kernel': ['rbf', 'sigmoid'], 'class_weight': ['balanced', {1: 10}, {1: 20}]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=make_scorer(matthews_corrcoef), verbose=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grid Search 2\n",
    "calculate_MCC = make_scorer(matthews_corrcoef)\n",
    "\n",
    "parameters = [\n",
    "  {'C': [0.1, 1, 10, 100], 'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5], 'kernel': ['rbf','sigmoid'], 'class_weight':['balanced',{1:10},{1:20}]}\n",
    "]\n",
    "\n",
    "gridSVM = svm.SVC()\n",
    "grid_search2 = GridSearchCV(gridSVM, parameters, scoring=calculate_MCC)\n",
    "grid_search2.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search 3\n",
    "calculate_MCC = make_scorer(matthews_corrcoef)\n",
    "\n",
    "parameters = [\n",
    "  {'C': [0.1, 1, 10, 100], 'gamma': [1e-4, 1e-3, 0.01, 0.1, 0.2, 0.5], 'kernel': ['poly'], 'class_weight':['balanced',{1:10},{1:20}],'degree':[1,3,5], 'coef0':[1.0, 2.0]}\n",
    "]\n",
    "\n",
    "gridSVM = svm.SVC()\n",
    "grid_search3 = GridSearchCV(gridSVM, parameters, scoring=calculate_MCC)\n",
    "grid_search3.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame(grid_search1.cv_results_)\n",
    "grid_search1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Runs the classifier and outputs the metrics\n",
    "y_pred = svclassifier.predict(X_test)\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test,y_pred,labels=[1,-1]),'\\n')\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,y_pred,labels=[1,-1]),'\\n')\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, y_pred),'\\n')\n",
    "print('Matthew Correlation Coefficient:')\n",
    "print(matthews_corrcoef(y_test, y_pred),'\\n')\n",
    "prob = svclassifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve section\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, prob[:,1], pos_label=1, drop_intermediate=True)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "reg_per_img = (y_pred.size - 51) / 205\n",
    "fp = false_positive_rate * reg_per_img\n",
    "plt.plot(fp, true_positive_rate, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.xlim([-0,5])\n",
    "plt.ylim([-0,1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive per Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computations in order to properly scale the false positive ratio\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "regions = y.shape[0]\n",
    "neg_reg = counts[0]\n",
    "pos_reg = counts[1]\n",
    "num_img = 410\n",
    "reg_per_img = regions / num_img\n",
    "neg_reg_per_img = neg_reg / num_img\n",
    "neg_reg_per_img\n",
    "scaling = 5 / neg_reg_per_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Receiver Operating Characteristic (ROC) with cross validation\n",
    "cv = StratifiedKFold(n_splits=6)\n",
    "\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "\n",
    "i = 0\n",
    "matthew = 0\n",
    "for train, test in cv.split(X, y):\n",
    "    probas_ = svclassifier.fit(X[train], y[train]).predict_proba(X[test])\n",
    "    y_pred = svclassifier.predict(X[test])\n",
    "    matthew = matthew + matthews_corrcoef(y[test], y_pred)\n",
    "    \n",
    "    # Compute ROC curve and area the curve\n",
    "    fpr, tpr, thresholds = roc_curve(y[test], probas_[:, 1])\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    #fpr = neg_reg_per_img * fpr\n",
    "    \n",
    "    aucs.append(roc_auc)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3,\n",
    "             label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n",
    "\n",
    "    i += 1\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n",
    "         label='Luck', alpha=.8)\n",
    "\n",
    "#mean_fpr = mean_fpr * neg_reg_per_img\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=2, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,\n",
    "                 label=r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "print(matthew/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVM_classif = SVC(C=10, class_weight='balanced', kernel='linear', probability=True)\n",
    "clf = AdaBoostClassifier(SVM_classif,n_estimators=50,learning_rate=1, algorithm='SAMME.R')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Confusion matrix:')\n",
    "print(confusion_matrix(y_test,y_pred,labels=[1,-1]),'\\n')\n",
    "print('Classification report:')\n",
    "print(classification_report(y_test,y_pred,labels=[1,-1]),'\\n')\n",
    "print('Accuracy:')\n",
    "print(accuracy_score(y_test, y_pred),'\\n')\n",
    "print('Matthew Correlation Coefficient:')\n",
    "print(matthews_corrcoef(y_test, y_pred),'\\n')\n",
    "prob = clf.predict_proba(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
