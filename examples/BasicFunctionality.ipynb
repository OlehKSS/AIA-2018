{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intelligent Mammogram Mass Analysis and Segmentation (IMMAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import immas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immas.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to read one image and create MammogramImage file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from immas import MammogramImage\n",
    "\n",
    "path_image = \"../dataset/images/20587080_b6a4f750c6df4f90_MG_R_ML_ANON.tif\"\n",
    "path_mask = \"../dataset/masks/20587080_b6a4f750c6df4f90_MG_R_ML_ANON.png\"\n",
    "pectoral_muscle = \"../dataset/pectoral_muscle_masks/20587080_b6a4f750c6df4f90_MG_R_ML_ANON.tif\"\n",
    "\n",
    "# contructor will automatically read data, if contrary not specified\n",
    "# pectoral muscle will be removed from image if we have corresponding mask available\n",
    "mm = MammogramImage(path_image, path_mask, pmuscle_mask_path=pectoral_muscle)\n",
    "\n",
    "# check whether this image has ground truth segmentation result available\n",
    "if mm.has_masses:\n",
    "    print('Masses are present on ground truth image')\n",
    "else:\n",
    "    print('No masses on ground truth image are present')\n",
    "\n",
    "# attribute .image_data contains actual image cropped according to the masks    \n",
    "plt.imshow(mm.image_data, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title('Cropped image')\n",
    "plt.show()\n",
    "\n",
    "#attribute .image_data contains actual image cropped according to the masks   \n",
    "plt.imshow(mm.uncropped_image, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title('Uncropped image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mm.image_ground_truth, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title('Ground truth image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to read whole dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from immas.io import read_dataset\n",
    "import cv2\n",
    "\n",
    "data_set = read_dataset(image_folder=\"../dataset/images\",\n",
    "            mask_folder=\"../dataset/masks\",\n",
    "            results_folder=\"../dataset/groundtruth\",\n",
    "            pmuscle_mask_folder=\"../dataset/pectoral_muscle_masks\")\n",
    "\n",
    "print(\"Number of images for training is {0}, number of images for testing is {1}\".format(\n",
    "    len(data_set[\"train\"]), len(data_set[\"test\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's show an example image from train subset of images, that has also a ground truth image\n",
    "for img in data_set[\"train\"]:\n",
    "    mammogram = img\n",
    "    mammogram.read_data()\n",
    "    break\n",
    "\n",
    "\n",
    "plt.imshow(mammogram.image_data, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title('Cropped image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mammogram.uncropped_image, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title('Uncropped image')\n",
    "plt.show()\n",
    "\n",
    "plt.imshow(mammogram.image_ground_truth, cmap=\"gray\")\n",
    "plt.axis('off')\n",
    "plt.title('Ground truth')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Enhancement - PreProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines function to apply preprocessing techniques.\n",
    "# This can be used to try different parameters for the preprocessing functions.\n",
    "# Also can be used to try those functions in different orders.\n",
    "\n",
    "from immas import preprocessing\n",
    "\n",
    "def testPreProcessing (img):\n",
    "    img = preprocessing.resize(img)\n",
    "    #img = preprocessing.open(img)\n",
    "    #img = preprocessing.close(img)\n",
    "    #img = preprocessing.erode(img)\n",
    "    #img = preprocessing.dilate(img)\n",
    "    #img = preprocessing.clahe(img)\n",
    "    img = preprocessing.morphoEnhancement(img)\n",
    "    img = preprocessing.waveletTransform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applies the preprocessing techniques defined above in the entire dataset (both training and test sets)\n",
    "\n",
    "img = data_set[\"train\"]\n",
    "for m in img:\n",
    "    m.read_data()\n",
    "    m.image_data = testPreProcessing(m.image_data)\n",
    "    #plt.imshow(m.image_data, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "img = data_set[\"test\"]\n",
    "for m in img:\n",
    "    m.read_data()\n",
    "    m.image_data = preprocessing.fullPreprocessing(m.image_data)\n",
    "\n",
    "# plt.imshow(m.image_data, cmap=\"gray\")\n",
    "# cv2.imwrite('preprocessed_img.png',m.image_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (IMMAS)",
   "language": "python",
   "name": "immas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
